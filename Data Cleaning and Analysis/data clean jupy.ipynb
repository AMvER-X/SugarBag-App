{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import pygwalker as pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths_sugar_bag = {\n",
    "    'weather_station': './SugarBag/SugarBagRd_Atmos_Aggregated.csv',\n",
    "    'wifi_counter': './SugarBag/SugarBagRd_NCount_Aggregated.csv',\n",
    "    'object_detection': './SugarBag/Alpha_X_Aggregated.csv',\n",
    "    'infrared_bi_directional': './SugarBag/SugarBagRd_Farmo_Aggregated.csv',\n",
    "    'infrared_counters': './SugarBag/SugarBagRd_DingTek_Aggregated.csv',\n",
    "    'vibration_counters': './SugarBag/SugarBagRd_R718mbb_Aggregated.csv'\n",
    "\n",
    "}\n",
    "\n",
    "def load_dataset(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "sugar_bag_data = { sensor: load_dataset(path) for sensor, path in file_paths_sugar_bag.items()}\n",
    "\n",
    "local_time = pd.to_datetime(\"2023-01-21 10:00:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_info = pd.DataFrame({\"Name\":[\"Aero\",\"Bees Knees\",\"Black Schute\",\"Boner log line\",\"Bottom Powerline Access Trail\",\"Fantales\",\"Golden Rough\",\"Honeycomb\",\"Milky Way\",\"Party mix\",\"Playground\",\"Playground climb trail\",\"Rocky Road\",\"Sour Power\",\"Sweet Sugar\",\"Syrup\",\"The Drop In Clinic\",\"Willy Wonka\"],\n",
    "                               \"Difficulty\":[\"Double Black\",\"Blue\",\"Black\",\"Black\",\"Green\",\"Green\",\"Black\",\"Blue\",\"Green\",\"Green\",\"Double Black\",\"Blue\",\"Black\",\"Green\",\"Blue\",\"Blue\",\"Double Black\",\"Blue\"],\n",
    "                               \"TrailType\":[\"Freeride\",\"Freeride\",\"Shortcut\",\"Shortcut\",\"Access Trail\",\"Freeride\",\"Freeride\",\"Freeride\",\"Access Trail\",\"Freeride\",\"Freeride/Multiline\",\"Access Trail\",\"Freeride\",\"Access Trail\",\"Freeride\",\"Freeride\",\"Freeride\",\"Freeride\"],\n",
    "                               \"Device\":[\"NA\",\"dc500-385c\",\"dc500-4402\",\"NA\",\"NA\",\"NA\",\"fpc-4f48\",\"NA\",\"fpc-4f48\",\"dc500-540f\",\"fpc-da3a?\",\"NA\",\"NA\",\"fpc-da3a\",\"NA\",\"fpc-7559\",\"NA\",\"NA\"],\n",
    "                               \"Counter\":[\"NA\",\"nonNegPeopleCount\",\"nonNegPeopleCount\",\"NA\",\"NA\",\"NA\",\"nonNegDifCount2\",\"NA\",\"nonNegDifCount1\",\"nonNegPeopleCount\",\"nonNegDifCount2?\",\"NA\",\"NA\",\"nonNegDifCount1\",\"NA\",\"nonNegDifCount1\",\"NA\",\"NA\"]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPEN AND REMOVE UNNECESSARY DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" please update these as reqired\n",
    "\"\"\"\n",
    "\n",
    "def open_and_clean_Weather(): # Updated connor's version\n",
    "    df =sugar_bag_data['weather_station']\n",
    "    # Format time\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "    if df.isnull().values.any():\n",
    "        df.ffill( inplace = True)\n",
    "\n",
    "    # Drop unneeded columns\n",
    "    if 'airTemeratureDiff' in df:\n",
    "        df.drop(columns = ['airTemeratureDiff'], inplace = True)\n",
    "    if 'atmosphericPressureDiff' in df:\n",
    "        df.drop(columns = ['atmosphericPressureDiff'], inplace = True)\n",
    "    if 'gustSpeedDiff' in df:\n",
    "        df.drop(columns = ['gustSpeedDiff'], inplace = True)\n",
    "    if 'relativeHumidityDiff' in df:\n",
    "        df.drop(columns = ['relativeHumidityDiff'], inplace = True)\n",
    "    if 'windSpeedDiff' in df:\n",
    "        df.drop(columns = ['windSpeedDiff'], inplace = True)\n",
    "    if 'windDirectionDiff' in df:\n",
    "        df.drop(columns = ['windDirectionDiff'], inplace = True)\n",
    "    if 'windDirection' in df:\n",
    "        df.drop(columns = ['windDirection'], inplace = True)\n",
    "    \n",
    "    #Remove duplicate entries\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "def open_and_clean_WIFI(): #connor's version\n",
    "    # open data\n",
    "    df =sugar_bag_data['wifi_counter']\n",
    "    # Formatting time\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "    # Check if data frame has null values\n",
    "    if df.isnull().values.any():\n",
    "        df.ffill( inplace = True)\n",
    "\n",
    "    # Drop uneeded columns\n",
    "    if 'currentDiff' in df:\n",
    "        df.drop(columns = ['currentDiff'], inplace = True)\n",
    "    if 'newDiff' in df:\n",
    "        df.drop(columns = ['newDiff'], inplace = True)\n",
    "    if 'totalDiff' in df:\n",
    "        df.drop(columns = ['totalDiff'], inplace = True)\n",
    "\n",
    "    # Remove duplicate entries\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Remove invalid entries\n",
    "    for index, row in df.iterrows():\n",
    "        if row['new'] < 0:\n",
    "            df.loc[index, 'new'] = 0\n",
    "        if row['current'] < 0:\n",
    "            df.loc[index, 'current'] = 0\n",
    "        if row['total'] < 0:\n",
    "            df.loc[index, 'total'] = 0\n",
    "\n",
    "    return df\n",
    "\n",
    "def open_and_clean_OBJ(): # Updated connor's version\n",
    "    # open data\n",
    "    df =sugar_bag_data['object_detection']\n",
    "    # Formatting time\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "    # Check if data frame has null values\n",
    "    if df.isnull().values.any():\n",
    "        df.ffill( inplace = True)\n",
    "\n",
    "    # Drop uneeded columns\n",
    "    if 'F1 - peopleLeft/Up' in df:\n",
    "        df.drop(columns = ['F1 - peopleLeft/Up'], inplace = True)\n",
    "    if 'F2 - peopleRight/Down' in df:\n",
    "        df.drop(columns = ['F2 - peopleRight/Down'], inplace = True)\n",
    "    if 'F9 - trucksLeft/Up' in df:\n",
    "        df.drop(columns = ['F9 - trucksLeft/Up'], inplace = True)\n",
    "    if 'F10 - trucksRight/Down' in df:\n",
    "        df.drop(columns = ['F10 - trucksRight/Down'], inplace = True)\n",
    "  \n",
    "\n",
    "    # Remove duplicate entries\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Remove invalid entries\n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"F3 - bikesLeft/Up\"] < 0:\n",
    "            df.loc[index, 'F3 - bikesLeft/Up'] = 0\n",
    "        if row['F4 - bikesRight/Down'] < 0:\n",
    "            df.loc[index, 'F4 - bikesRight/Down'] = 0\n",
    "        if row[\"F5 - carsLeft/Up\"] < 0:\n",
    "            df.loc[index, 'F5 - carsLeft/Up'] = 0\n",
    "        if row['F6 - carsRight/Down'] < 0:\n",
    "            df.loc[index, 'F6 - carsRight/Down'] = 0\n",
    "        if row[\"F7 - busesLeft/Up\"] < 0:\n",
    "            df.loc[index, 'F7 - busesLeft/Up'] = 0\n",
    "        if row['F8 - busesRight/Down'] < 0:\n",
    "            df.loc[index, 'F8 - busesRight/Down'] = 0\n",
    "        \n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "def open_and_clean_IRBD():\n",
    "    df =sugar_bag_data[\"infrared_bi_directional\"]\n",
    "    # Formatting time\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "    # Check if data frame has null values\n",
    "    if df.isnull().values.any():\n",
    "        df.ffill( inplace = True)\n",
    "    \n",
    "    # Drop uneeded columns\n",
    "    if 'battery' in df:\n",
    "        df.drop(columns = ['battery'], inplace = True)\n",
    "    if 'count1' in df:\n",
    "        df.drop(columns = ['count1'], inplace = True)\n",
    "    if 'count2' in df:\n",
    "        df.drop(columns = ['count2'], inplace = True)\n",
    "    if 'activity' in df:\n",
    "        df.drop(columns = ['activity'], inplace = True)\n",
    "\n",
    "    # Remove duplicate entries\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Remove invalid entries and cap entries at 200\n",
    "    for index, row in df.iterrows():\n",
    "        if row['nonNegDifCount1'] < 0:\n",
    "            df.loc[index, 'nonNegDifCount1'] = 0\n",
    "        elif row['nonNegDifCount1'] > 200:\n",
    "            df.loc[index, 'nonNegDifCount1'] = 200\n",
    "        if row['nonNegDifCount2'] < 0:\n",
    "            df.loc[index, 'nonNegDifCount2'] = 0\n",
    "        elif row['nonNegDifCount2'] > 200:\n",
    "            df.loc[index, 'nonNegDifCount2'] = 200\n",
    "        if row['nonNegDigActivity'] < 0:\n",
    "            df.loc[index, 'nonNegDigActivity'] = 0\n",
    "        elif row['nonNegDigActivity'] > 200:\n",
    "            df.loc[index, 'nonNegDigActivity'] = 200\n",
    "        \n",
    "\n",
    "    return df\n",
    "\n",
    "def open_and_clean_IRC():\n",
    "    df =sugar_bag_data[\"infrared_counters\"]\n",
    "    # Formatting time\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "    # Check if data frame has null values\n",
    "    if df.isnull().values.any():\n",
    "        df.ffill( inplace = True)\n",
    "\n",
    "    # Drop uneeded columns\n",
    "    if 'battery' in df:\n",
    "        df.drop(columns = ['battery'], inplace = True)\n",
    "  \n",
    "    # Remove duplicate entries\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Remove invalid entries\n",
    "    for index, row in df.iterrows():\n",
    "        if row['peopleCount'] < 0:\n",
    "            df.loc[index, 'peopleCount'] = 0\n",
    "        if row[\"nonNegPeopleCount\"] < 0:\n",
    "            df.loc[index, 'nonNegPeopleCount'] = 0\n",
    "\n",
    "    return df\n",
    "\n",
    "def open_and_clean_VC(): \n",
    "    df =sugar_bag_data[\"'vibration_counters'\"]\n",
    "\n",
    "    # Formatting time\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "    # Check if data frame has null values\n",
    "    if df.isnull().values.any():\n",
    "        df.ffill( inplace = True)\n",
    "\n",
    "    # Drop uneeded columns\n",
    "    if 'battery' in df:\n",
    "        df.drop(columns = ['battery'], inplace = True)\n",
    "    if 'batteryDiff' in df:\n",
    "        df.drop(columns = ['batteryDiff'], inplace = True)\n",
    "    if 'workCount' in df:\n",
    "        df.drop(columns = ['workCount'], inplace = True)\n",
    "        \n",
    "    # Remove duplicate entries\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Remove duplicate entries\n",
    "    for index, row in df.iterrows():\n",
    "        if row['workCountDiff'] < 0:\n",
    "            df.loc[index, 'workCountDiff'] = 0\n",
    "\n",
    "    return df\n",
    "\n",
    "def open_and_clean_VC(): \n",
    "    df =sugar_bag_data[\"vibration_counters\"]\n",
    "\n",
    "    # Formatting time\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "    # Check if data frame has null values\n",
    "    if df.isnull().values.any():\n",
    "        df.ffill( inplace = True)\n",
    "\n",
    "    # Drop uneeded columns\n",
    "    if 'battery' in df:\n",
    "        df.drop(columns = ['battery'], inplace = True)\n",
    "    if 'batteryDiff' in df:\n",
    "        df.drop(columns = ['batteryDiff'], inplace = True)\n",
    "    if 'workCount' in df:\n",
    "        df.drop(columns = ['workCount'], inplace = True)\n",
    "        \n",
    "    # Remove duplicate entries\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Remove duplicate entries\n",
    "    for index, row in df.iterrows():\n",
    "        if row['workCountDiff'] < 0:\n",
    "            df.loc[index, 'workCountDiff'] = 0\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TIME MANUPULATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Change the date or time\n",
    "a string value that is formatted like the date, time, or both \n",
    "0000-00-00 00:00:00\n",
    "\n",
    "an error with the code, is_valid_datetime is validating every date or time value, but if not full datetime given, then computer assigns a value when not wanted.\n",
    "\"\"\"\n",
    "def set_datetime(time):\n",
    "    global local_time\n",
    "    time = pd.to_datetime(time)\n",
    "    date_part = local_time.date()\n",
    "    time_part = local_time.time()\n",
    "\n",
    "    \n",
    "    if is_valid_datetime(time) == True:\n",
    "        local_time = time\n",
    "    elif is_valid_date(time) == True:\n",
    "        date_part = time\n",
    "        local_time =dt.combine(date_part, time_part)\n",
    "    elif is_valid_time(time) == True:\n",
    "        time_part = time\n",
    "        local_time =dt.combine(date_part, time_part)\n",
    "        print(local_time)\n",
    "    else:\n",
    "        print(\"\"\"there is an error with your date imput. \n",
    "no changes made\"\"\")\n",
    "        \n",
    "\n",
    "\"\"\"Validates the given date, time, or both\"\"\" \n",
    "def is_valid_datetime(date_time, format=\"%Y-%m-%d %H:%M:%S\"):\n",
    "    date_timestr =date_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    try:\n",
    "        # Try to parse the datetime string with the given format\n",
    "        dt.strptime(date_timestr, format)\n",
    "        print(\"ping\")\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "        \n",
    "def is_valid_date(date, format=\"%Y-%m-%d\"):\n",
    "    datestr =date.strftime('%H:%M:%S')\n",
    "    try:\n",
    "        # Try to parse the datetime string with the given format\n",
    "        dt.strptime(datestr, format)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def is_valid_time(time, format=\"%H:%M:%S\"):\n",
    "    timestr =time.strftime('%H:%M:%S') #converts the timestamp into a string \n",
    "    try:\n",
    "        # Try to parse the datetime string with the given format\n",
    "        dt.strptime(timestr, format)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "\"\"\"function to remove min and second from the time stamp\n",
    "STATUS : INCOMPLETE\n",
    "\"\"\"\n",
    "def to_nearest_hr(time):\n",
    "\n",
    "\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "find the distinct devices based on the dev_id\n",
    "\n",
    "STATUS: WORKING\n",
    "\"\"\"\n",
    "def find_devices(df):\n",
    "    dev_id_col = df[\"dev_id\"]\n",
    "    distinct_dev =[]\n",
    "\n",
    "    for device in dev_id_col: \n",
    "        if device not in distinct_dev: \n",
    "            distinct_dev.append(device) \n",
    "\n",
    "    return distinct_dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''seperate the different devices into different columns.\n",
    "\n",
    "STATUS: WORKING\n",
    "'''\n",
    "def seperate_devices(df):\n",
    "    distinct =find_devices(df)\n",
    "    split_list = {}\n",
    "\n",
    "    for device in distinct:\n",
    "        var_name = \"%s\" % device\n",
    "        df_device = df.loc[df[\"dev_id\"]==device].copy()\n",
    "        df_device.drop(columns = [\"dev_id\"],inplace= True)\n",
    "        split_list[var_name] = df_device\n",
    "    \n",
    "    #print(\"this is the fpc-6460 data \",split_list[\"fpc-6460\"]) #check \n",
    "    return split_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"function to show from a selcected date for a given number of days, of a given datafrme\n",
    "STATUS: WORKING\n",
    "\"\"\"\n",
    "def cut_view(df,start,span):\n",
    "    start = pd.to_datetime(start)\n",
    "    end = start + pd.DateOffset(days=span)\n",
    "    #remove dates before\n",
    "    filtered_df = df[df['datetime'] >= start]\n",
    "    #remove dates after the given timeframe\n",
    "    filtered_df = df[df['datetime'] <= end]\n",
    "\n",
    "    return filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ensures datetime is a value and readable\n",
    "\n",
    "STATUS: WORKING UNUSED\n",
    "'''\n",
    "def format_DT(df):\n",
    "     \n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    #df['Date']= pd.to_datetime(df['datetime']).dt.date\n",
    "    #print(df[\"Date\"].head())\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_date(df):\n",
    "\n",
    "    df['Date']= pd.to_datetime(df['datetime']).dt.date\n",
    "    #print(df[\"Date\"].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Merges the columns based on the date, and sums each column for every day. \n",
    "works with dictionary\n",
    "\n",
    "STATUS: WORKING\n",
    "\"\"\"\n",
    "def daily_totals(df):\n",
    "    devices_inDict =seperate_devices(df)\n",
    "    dict_key = list(devices_inDict.keys())\n",
    "    daily = {}\n",
    "\n",
    "    for i in dict_key:  \n",
    "        total_PDay = devices_inDict[i].set_index('datetime').groupby(pd.Grouper(freq=\"D\")).sum() #groups by the calander date'\n",
    "        total_PDay['Date'] = total_PDay.index\n",
    "        total_PDay[\"day_name\"] = total_PDay[\"Date\"].dt.day_name()\n",
    "        daily[i]= total_PDay \n",
    "\n",
    "    \n",
    "        print(daily[i])\n",
    "    \n",
    "    return daily\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "merges cells based on the date by the frequency given in 'letter'\n",
    "uses the grouper function's frequency \n",
    "\n",
    "STATUS: ASSUMED WORKING. not stress tested\n",
    "\"\"\"\n",
    "def totals(df,letter= \"D\"):\n",
    "    devices_inDict =seperate_devices(df)\n",
    "    dict_key = list(devices_inDict.keys())\n",
    "    new = {}\n",
    "\n",
    "    for i in dict_key:  \n",
    "        total_PDay = devices_inDict[i].set_index('datetime').groupby(pd.Grouper(freq=letter)).sum() #groups by the calander date'\n",
    "        new[i]= total_PDay \n",
    "        print(new[i])\n",
    "    \n",
    "    return new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "get a subplot based off the chosen day of the week\n",
    "\n",
    "STATUS: INCOMPLETE\n",
    "\"\"\"\n",
    "def specific_day(df, day):\n",
    "    df.drop(df[~(df['day_name'] == day)].index)\n",
    "    print(\"new day column\")\n",
    "    print(df.head())\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"create a dictionary with all the devices\"\"\"\n",
    "def merger():\n",
    "    \n",
    "    weather = open_and_clean_Weather()\n",
    "    weather_Clean = daily_totals(weather)\n",
    "    \n",
    "    WIFI = open_and_clean_WIFI()\n",
    "    WIFI_Clean = daily_totals(WIFI)\n",
    "    \n",
    "    OBJ = open_and_clean_OBJ()\n",
    "    OBJ_Clean = daily_totals(OBJ)\n",
    "    \n",
    "    IRBD = open_and_clean_IRBD()\n",
    "    IRBD_Clean = daily_totals(IRBD)\n",
    "\n",
    "    IRC = open_and_clean_IRC()\n",
    "    IRC_Clean = daily_totals(IRC)\n",
    "    \n",
    "    \"\"\"add names once formatted\"\"\"\n",
    "    device_list = weather_Clean|WIFI_Clean|OBJ_Clean|IRBD_Clean|IRC_Clean\n",
    "    \n",
    "    return device_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"create a dictionary with all the devices\"\"\"\n",
    "def device_dict():\n",
    "    \n",
    "    weather = open_and_clean_Weather()\n",
    "    weather_Clean = seperate_devices(weather)\n",
    "    \n",
    "    WIFI = open_and_clean_WIFI()\n",
    "    WIFI_Clean = seperate_devices(WIFI)\n",
    "    \n",
    "    OBJ = open_and_clean_OBJ()\n",
    "    OBJ_Clean = seperate_devices(OBJ)\n",
    "    \n",
    "    IRBD = open_and_clean_IRBD()\n",
    "    IRBD_Clean = seperate_devices(IRBD)\n",
    "\n",
    "    IRC = open_and_clean_IRC()\n",
    "    IRC_Clean = seperate_devices(IRC)\n",
    "    \n",
    "    \"\"\"add names once formatted\"\"\"\n",
    "    device_list = weather_Clean|WIFI_Clean|OBJ_Clean|IRBD_Clean|IRC_Clean\n",
    "    \n",
    "    return device_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data():\n",
    "    Weather = open_and_clean_Weather()\n",
    "\n",
    "    WIFI = open_and_clean_WIFI()\n",
    "\n",
    "    OBJ = open_and_clean_OBJ()\n",
    "\n",
    "    IRBD = open_and_clean_IRBD()\n",
    "\n",
    "    IRC = open_and_clean_IRC()\n",
    "\n",
    "    VC = open_and_clean_VC()\n",
    "\n",
    "    SB_Clean = {\n",
    "    'weather_station': Weather,\n",
    "    'wifi_counter':WIFI,\n",
    "    'object_detection': OBJ,\n",
    "    'infrared_bi_directional': IRBD,\n",
    "    'infrared_counters': IRC,\n",
    "    'vibration_counters': VC}\n",
    "\n",
    "\n",
    "    return SB_Clean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_riders(): \n",
    "    global local_time\n",
    "    data = clean_data()\n",
    "    wificounter = data[\"wifi_counter\"]\n",
    "\n",
    "    if local_time < pd.to_datetime(\"2024-03-01 00:00:00\"): #this negates a time error found before this date\n",
    "        edited_time = local_time + pd.DateOffset(hours= 14)\n",
    "    else:\n",
    "        edited_time = local_time\n",
    "    #get the current users. \"current\" or \"total\" to be used, total sometimes reather high and unsure if this is correct\n",
    "    current_users = wificounter.loc[wificounter[\"datetime\"] ==edited_time, \"current\"].values[0] \n",
    "    print(\"there are approx.\", current_users, \"people in the park\")\n",
    "    return current_users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are approx. 3.0 people in the park\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"test code to access how many riders have ridden the trail \"\"\"\n",
    "def trail_heads(trail,column): \n",
    "    global local_time\n",
    "    time = local_time\n",
    "    data = device_dict()\n",
    "    iotdevice = data[trail]\n",
    "    \n",
    "    #infomation = data[trail].loc[:,\"datetime\" ]\n",
    "    riders = iotdevice.loc[iotdevice[\"datetime\"] ==time, column].values[0]\n",
    "    print(\"there are approx.\", riders, \"on TRAIL NAME\")\n",
    "    return riders\n",
    "\n",
    "\n",
    "local_time = pd.to_datetime(\"2023-01-21 10:00:00\")\n",
    "trail_heads(\"fpc-4f48\",'nonNegDifCount1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are approx. 1.0 people on: Bees Knees\n"
     ]
    }
   ],
   "source": [
    "def get_trail_numbers(trail_name): \n",
    "    #global local_time\n",
    "    time = local_time\n",
    "    trail_device = trail_info.loc[trail_info[\"Name\"]== trail_name,\"Device\"].values[0]\n",
    "    trail_count = trail_info.loc[trail_info[\"Name\"]== trail_name,\"Counter\"].values[0]\n",
    "    data = device_dict()\n",
    "    iotdevice = data[trail_device]\n",
    "\n",
    "    \n",
    "   \n",
    "    no_riders = iotdevice.loc[iotdevice[\"datetime\"] ==time, trail_count].values[0]\n",
    "    print(\"there are approx.\", no_riders, \"people on:\", trail_name)\n",
    "    #return riders\n",
    "#get_trail_numbers(\"Bees Knees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''basic plotting function'''\n",
    "\n",
    "def plotting(x, y, xlab ='x - axis', ylab ='y - axis', title='Graph Title'):\n",
    "    \n",
    "    plt.plot(x,y)       #plot the x and y values given\n",
    "    plt.xlabel(xlab)    #lable the x vaule, a given value or default 'x - axis'\n",
    "    plt.ylabel(ylab)    #lable the y vaule, a given value or default 'y - axis'\n",
    "    plt.title(title)    #lable the graph, a given value or default 'Graph Title'\n",
    "    plt.show()          #prints the graph in a window\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stuff():\n",
    "\n",
    "    all_devices = merger()\n",
    "\n",
    "    x = all_devices\n",
    "    y = 0\n",
    "    plotting(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST CASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the time is: 2023-01-15 10:00:00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m#set_datetime(\"2024-01-13 17:29:00\") #will provide an error due to min value\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m#total_riders()\u001b[39;00m\n\u001b[0;32m     16\u001b[0m local_time \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-01-15 10:00:00\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mtest_datemod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m    \n",
      "Cell \u001b[1;32mIn[91], line 4\u001b[0m, in \u001b[0;36mtest_datemod\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m local_time\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe time is:\u001b[39m\u001b[38;5;124m\"\u001b[39m,local_time)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mtotal_riders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m set_datetime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2024-04-12\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe time is:\u001b[39m\u001b[38;5;124m\"\u001b[39m,local_time)\n",
      "Cell \u001b[1;32mIn[75], line 3\u001b[0m, in \u001b[0;36mtotal_riders\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtotal_riders\u001b[39m(): \n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mglobal\u001b[39;00m local_time\n\u001b[1;32m----> 3\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mclean_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     wificounter \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwifi_counter\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m local_time \u001b[38;5;241m<\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2024-03-01 00:00:00\u001b[39m\u001b[38;5;124m\"\u001b[39m): \u001b[38;5;66;03m#this negates a time error found before this date\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[56], line 8\u001b[0m, in \u001b[0;36mclean_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m WIFI \u001b[38;5;241m=\u001b[39m open_and_clean_WIFI()\n\u001b[0;32m      6\u001b[0m OBJ \u001b[38;5;241m=\u001b[39m open_and_clean_OBJ()\n\u001b[1;32m----> 8\u001b[0m IRBD \u001b[38;5;241m=\u001b[39m \u001b[43mopen_and_clean_IRBD\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m IRC \u001b[38;5;241m=\u001b[39m open_and_clean_IRC()\n\u001b[0;32m     12\u001b[0m VC \u001b[38;5;241m=\u001b[39m open_and_clean_VC()\n",
      "Cell \u001b[1;32mIn[45], line 132\u001b[0m, in \u001b[0;36mopen_and_clean_IRBD\u001b[1;34m()\u001b[0m\n\u001b[0;32m    129\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# Remove invalid entries and cap entries at 200\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterrows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnonNegDifCount1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnonNegDifCount1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\n",
      "File \u001b[1;32mc:\\Users\\kylee\\OneDrive\\Documents\\GitHub\\Sugarbagtrack\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:1554\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1552\u001b[0m using_cow \u001b[38;5;241m=\u001b[39m using_copy_on_write()\n\u001b[0;32m   1553\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[1;32m-> 1554\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m using_cow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block:\n\u001b[0;32m   1556\u001b[0m         s\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39madd_references(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kylee\\OneDrive\\Documents\\GitHub\\Sugarbagtrack\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:584\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    582\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    586\u001b[0m     manager \u001b[38;5;241m=\u001b[39m _get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\kylee\\OneDrive\\Documents\\GitHub\\Sugarbagtrack\\.venv\\Lib\\site-packages\\pandas\\core\\construction.py:551\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    548\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    550\u001b[0m object_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mABCIndex\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    552\u001b[0m     object_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;66;03m# extract ndarray or ExtensionArray, ensure we have no NumpyExtensionArray\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kylee\\OneDrive\\Documents\\GitHub\\Sugarbagtrack\\.venv\\Lib\\site-packages\\pandas\\core\\dtypes\\generic.py:44\u001b[0m, in \u001b[0;36mcreate_pandas_abc_type.<locals>._instancecheck\u001b[1;34m(cls, inst)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_instancecheck\u001b[39m(\u001b[38;5;28mcls\u001b[39m, inst) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inst, \u001b[38;5;28mtype\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kylee\\OneDrive\\Documents\\GitHub\\Sugarbagtrack\\.venv\\Lib\\site-packages\\pandas\\core\\dtypes\\generic.py:37\u001b[0m, in \u001b[0;36mcreate_pandas_abc_type.<locals>._check\u001b[1;34m(inst)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_pandas_abc_type\u001b[39m(name, attr, comp):\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check\u001b[39m(inst) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(inst, attr, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_typ\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m comp\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# https://github.com/python/mypy/issues/1006\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error: 'classmethod' used with a non-method\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test_datemod():\n",
    "    global local_time\n",
    "    print(\"the time is:\",local_time)\n",
    "    total_riders()\n",
    "    set_datetime(\"2024-04-12\")\n",
    "    print(\"the time is:\",local_time)\n",
    "    total_riders()\n",
    "    set_datetime(\"2024-04-12 12:00:00\")\n",
    "    print(\"the time is:\",local_time)\n",
    "    total_riders()\n",
    "    set_datetime(\"17:00:00\") #\n",
    "    print(\"the time is:\",local_time)\n",
    "    total_riders()\n",
    "    #set_datetime(\"2024-01-13 17:29:00\") #will provide an error due to min value\n",
    "    #total_riders()\n",
    "local_time = pd.to_datetime(\"2023-01-15 10:00:00\")\n",
    "test_datemod()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trail_heads(\"fpc-4f48\",\"nonNegDifCount1\")\n",
    "aaaaaa = clean_data()\n",
    "#bbbb = aaaaaa[\"fpc-4f48\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are approx. 17 people in the park\n",
      "there are approx. 1 people in the park\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_SB = clean_data()\n",
    "test_data = cut_view(data_SB['infrared_bi_directional'],\"2023-01-15\",3)\n",
    "#pyg.walk(test_data)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
